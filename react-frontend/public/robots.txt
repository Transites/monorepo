# robots.txt - Controls web crawler access to the Transitos encyclopedia
# This file tells search engine crawlers which pages they can and cannot access.
# For the Transitos project, we allow all crawlers to access all pages to maximize
# discoverability of the Franco-Brazilian cultural content.

User-agent: Googlebot
Allow: /

User-agent: Bingbot
Allow: /

User-agent: Twitterbot
Allow: /

User-agent: facebookexternalhit
Allow: /

User-agent: *
Allow: /

# Sitemap location (when available)
# Sitemap: https://your-domain.com/sitemap.xml
